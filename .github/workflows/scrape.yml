name: Scrape Google Play Categories Daily

on:
  schedule:
    # Runs automatically once a day at midnight UTC
    - cron: '0 0 * * *' 
  # Allows you to click a button to run the script manually from the website
  workflow_dispatch: 

# Grants the workflow permission to push the parsed CSV back to your repo
permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run Python scraping script
        run: python scrape_categories_to_csv.py

      - name: Commit and push changes
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add google_play_apps.csv
          git diff --quiet && git diff --staged --quiet || (git commit -m "Automated update of google_play_apps.csv" && git push)

      - name: Upload to cPanel via FTP
        uses: SamKirkland/FTP-Deploy-Action@v4.3.5
        with:
          server: rankmyapps.com
          username: rankyggl
          password: gEK3g86pOdnH
          port: 21
          # The local file to upload
          local-dir: ./
          # The destination folder in your cPanel (from your JSON)
          server-dir: /public_html/
          # Only upload the CSV file
          exclude: |
            **/*
            !google_play_apps.csv